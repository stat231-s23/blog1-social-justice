---
title: "Decomposing Amherst Student Articles"
author: "Anna Zhou and Julia Woodward"
date: "May 2, 2023"
output:
  rmdformats::readthedown:
   highlight: "kate"
---

```{r setup, include = FALSE}
# Set code chunk defaults 
# Consider adding `message = FALSE` option
knitr::opts_chunk$set(echo = FALSE) 
                      
# Set R environment options
options(knitr.kable.NA = '')

# Load packages
library(knitr)
library(tidytext)
library(tidyverse)
library(wordcloud)
library(textdata)
library(ggplot2)
library(scales)
library(kableExtra)
```

# Intro

Amherst students have a wide range of interests, hobbies, and experiences. With a student body of only 1600, Amherst prides itself on this diversity. How is this diversity reflected in student writing? And what does this tell us about the priorities of the student body? To answer these questions, we analyzed 100 articles from the opinion section of [The Student](https://www.amherststudent.com/), the student magazine at Amherst College. The opinion section spans a large pool of topics, from health, to policy, to politics. We looked at the breakdown of these articles by subject matter, as well as the most common words and phrases referenced by these articles. We grouped articles by sentiment and emotion, and noticed changes in these areas over the past 8 months. 

```{r, fig.cap='Two issues of the Amherst Student from January 1960 (right) and April 2023 (left)', out.width="100%", fig.align="center"}
knitr::include_graphics("img/amherst_student.jpg")
```




# Categorizing by Topic

Our dataset includes 100 articles from the Student, ranging from September 2022 to April 2023. We categorized each article by topic by looking at key words in each title. For example, the "health" category groups articles together that have the words "illness", "health", "ableism", "cancer", or "pandemic" in their title. The "policy" category groups articles that address some college policy, whether it be the open curriculum, the structure of the AAS, or J-term classes, to name a few. We observe that around 10% of the articles address college policy and 10% address politics. Furthermore, articles about policy and politics are around twice as common as articles about health or finances.

These topics are not mutually exclusive; for example, an article about the college's response to covid would be grouped under both "policy" and "health". 

```{r ggplot-example, fig.align="left", out.width="100%"}
opinions <- read_csv("data/opinions.csv", show_col_types = FALSE)

Title = opinions %>% select("Title")
all_words_in_titles <- Title %>%
  unnest_tokens(output = word, input = Title)

policy <- all_words_in_titles %>% filter(word == "AAS" | word == "requirements" | word == "attendance"| word == "curriculum"| word == "constitution"| word == "j-term"| word == "mask"| word == "class"| word == "covid" | word == "space" | word == "policies" | word == "haven")

finances <- all_words_in_titles %>% filter(word == "aid" | word == "tuition"| word == "pay"| word == "money" | word == "fee" | word == "financial")

health <- all_words_in_titles %>% filter(word == "illness" | word == "health"| word == "ableism" | word == "cancer" | word == "pandemic" | word == "mask" | word == "bruce")

politics <- all_words_in_titles %>% filter(word == "macro-" | word == "tragedy" | word == "columbus" | word == "israel" | word == "insider" | word == "discourse")

sports <- all_words_in_titles %>% filter(word == "bruce" | word == "badminton")

topics <- c("policy", "health", "finances", "politics", "sports")
count <- c(as.numeric(count(policy)), as.numeric(count(health)), as.numeric(count(finances)), as.numeric(count(politics)), as.numeric(count(sports)))
title_topics <- data.frame(topics, count)
kable(title_topics)

ggplot(data = title_topics, aes(x= topics, y = count, color = topics, fill = topics)) + 
  geom_col() + 
  labs(
    x = "Topics",
    y = "Number of articles",
    title = "Categorizing The Student articles by Title")

```


## Word and Phrase Frequency

What words and phrases are most common in the articles? We can plot the frequency of the most common words in the article bodies, after filtering out the stop-words (as, is, the, etc). "Student/s" and "Amherst" come out on top by a wide margin - no surprises there! "Student" is mentioned almost 400 times in just 100 articles. Other commonly appearing words are "time", "campus", and "college". 
```{r}
#finding most common terms in the body section
Body = opinions %>% select("Body")

all_words_in_body <- Body %>%
  unnest_tokens(output = word, input = Body)


body_words <- all_words_in_body %>% 
  filter(word != "student"  & word!= "it’s") %>%
  anti_join(stop_words, by="word")

body_words %>%
  count(word, sort = TRUE) %>% 
  slice(1:10) %>%
  ggplot(aes(x = fct_reorder(word, n), y = n, color = word, fill = word)) +
  geom_col() +
  # Rotate graph
  coord_flip() +
  guides(color = "none", 
         fill = "none") +
  labs(
    x = NULL,
    y = "Number of instances",
    title = "Most common words in Amherst Student Opinion Articles")
```

```{r}
#creating word cloud

opinion_word_freqs <- opinions %>%
  unnest_tokens(output = word, input = Body) %>%
  anti_join(stop_words, by = "word") %>%
  filter(word != "student" & word != "it’s" & word != "i’m" & word != "don’t" & word != "i’ve") %>%
  count(word, sort = TRUE)

#setting seed for reproducibility
set.seed(100)

#choosing color palette
my_palette <- brewer.pal(10, "Dark2")

opinion_word_freqs %>%
  with(wordcloud(words = word,
      freq = n,
      min.freq = 20,
      max.words = 50,
    # Plot the words in a random order
      random.order = TRUE,
    # Specify the range of the size of the words
      scale = c(2, 0.3),
# Specify proportion of words with 90 degree rotation 
      rot.per = 0.15,
# Color words from least to most frequent
      colors = my_palette,
# Change font family
      family = "sans"))
```

We also looked at the most common bigrams, or two word phrases, in the Student. The three most common bigrams are "Student body", "latin honors", and "mental health". This is in agreement with Figure 1, which illustrates that policy and health lie among the most common article topics. 

```{r}
#finding most common bigrams (2-term phrases)
#creating bigram token 
opinions_bigrams <- Body %>%
  unnest_tokens(output = bigram, input = Body, token = "ngrams", n = 2)

opinions_bigrams_clean <- opinions_bigrams %>%
  separate(col="bigram", into=c("word1", "word2"), sep=" ", remove=FALSE) %>%
  anti_join(stop_words, by=c("word1"="word")) %>%
  anti_join(stop_words, by=c("word2"="word")) %>%
  filter(!is.na(bigram)) %>%
  #removing irrelevant/uninformative bigrams
  filter((!grepl("amherst|editorial board|email protected|articles comment|emailing email", bigram))) %>%
  count(bigram, sort = TRUE) %>%
  slice(1:10)

#plotting most common bigrams
ggplot(opinions_bigrams_clean, aes(x = fct_reorder(bigram, n), y = n
                                , color = bigram, fill = bigram)) +
geom_col() +
# Rotate graph 
  coord_flip() + guides(color = "none",
         fill = "none") +
  labs(
x = NULL,
    y = "Number of instances",
    title = "Most common bigrams in Amherst Student Opinion articles")
```

# Categorizing by Sentiment and Emotion

We also analyzed the overall sentiment of these articles, and how this has changed over time. Has student writing become more positive or negative over the past 9 months?

## AFINN Lexicon

The AFINN Lexicon assigns each word or term a value, or "sentiment score" from -5 to 5, with 5 being the most positive. The table below shows that most terms in the articles are neutral to slightly positive.  
```{r}
afinn_lexicon <- get_sentiments("afinn")

#creating dataset using afinn lexicon grouped by date
suppressMessages(opinion_afinn <- opinions %>%
  unnest_tokens(word, Body) %>%
  anti_join(get_stopwords(), by = "word") %>%
  inner_join(get_sentiments("afinn")))

#getting word count for each sentiment value (-5 to 5)
opinion_afinn_count <- opinion_afinn %>%
  count(value)

#displaying table
kable(opinion_afinn_count)

#displaying barplot
ggplot(opinion_afinn_count, aes(x = value, y = n, fill = value)) +
  geom_col() +
  labs(
    x = "Sentiment",
    y = "Number of words in Student Opinion Articles",
    title = "Sentiment value according to AFINN Lexicon")
```
Over time, there appears to be no drastic change in overall sentiment. Overall sentiment peaked at the end of the fall semester in December, which had sentiment scores of around 300. During the Spring semester, however, the sentiment seemed to be growing more negative. Of course, more significant conclusions would require a much larger dataset.
```{r}
#plotting graph of sentiment in articles over time
opinion_narrative <- opinion_afinn %>%
  group_by(Date) %>%
  summarize(sentiment = sum(value))
  
ggplot(opinion_narrative, aes(x = Date, y = sentiment)) + 
  geom_point() + 
  scale_x_date(breaks = date_breaks("months"), labels = date_format("%B")) +
  geom_smooth() +  
  labs(title = "Sentiment in The Student Over Time by Issue Release Date Using AFINN Lexicon", subtitle = ("9/14/2022 - 4/26/2023"))
```

```{r}
# overall sentiment score
opinion_afinn %>%
  summarize(total_score = sum(value))

# by article
afinn_byarticles <- opinion_afinn %>%
  group_by(Title) %>%
  summarize(article_score = sum(value))
ggplot(data = afinn_byarticles, aes(x = article_score)) +
  geom_density(color="#AF7AC5", fill="#AF7AC5", alpha = 0.5) +
  theme_classic() +
  labs(title = "Total Article Sentiment Score based on AFINN Lexicon", x = "Article Sentiment Score")
```

```{r}
# overall favstats by article -- median of 29 is positive
mosaic::favstats(~article_score, data=afinn_byarticles)
```

```{r}
#AFINN sentiment for articles about Amherst policies

policy_words <- opinions %>%
  filter(str_detect(str_to_lower(Title), "policy|policies|financial aid|curriculum|case|fee|requirements|tuition|ableism")) %>%
  unnest_tokens(output=word, input=Body, token="words") %>%
  anti_join(stop_words, by="word") %>%
  inner_join(afinn_lexicon, by="word") %>%
  group_by(Title) %>%
  mutate(seq=row_number())

ggplot(policy_words, aes(x=seq, y=value)) +
  geom_line() +
  geom_hline(yintercept=0, lty="dashed", color="red") +
  facet_wrap(~Title, labeller = labeller(Title = label_wrap_gen(width = 23))) +
  labs(x="Order", y="AFINN Sentiment")
```

## NRC Lexicon

```{r}
nrc_lexicon <- get_sentiments("nrc")

# identify words in word_frequencies dataset (which has stop words removed) that are not in the lexicon
nrc_missed_words <- opinion_word_freqs %>%
  anti_join(nrc_lexicon, by = "word")

# proportion missed
nrow(nrc_missed_words)/nrow(opinion_word_freqs)
```

Beware -- over 79% of the words in the Amherst Student articles are not found in the nrc lexicon.

```{r}
#top words by sentiment
nrc_opinions <- opinion_word_freqs %>%
  inner_join(nrc_lexicon, by = "word") %>%
  filter(sentiment %in% c("positive", "negative", "anger", "disgust"
                          , "joy", "sadness")) %>%
  arrange(sentiment, desc(n)) %>%
  group_by(sentiment) %>%
  slice(1:10)

#plotting top 10 words under each sentiment
ggplot(data=nrc_opinions, aes(x = reorder(word,n), y = n, fill = as.factor(n))) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "Frequency") +
  facet_wrap(~ sentiment, ncol = 2, scales = "free") +
  coord_flip()
```



```{r}

suppressMessages(opinions_nrc <- opinions %>%
  unnest_tokens(word, Body) %>%
  #removing most common irrelevant/incorrectly classified words
  filter(word != "liberal" & word != "rail" & word != "anonymous" & word != "pay" & word != "president" & word != "question" & word != "library") %>%
  anti_join(get_stopwords(), by = "word") %>%
  inner_join(get_sentiments("nrc"), multiple = "all"))

#creating dataset with top30 most frequent words classified as negative
nrc_negative <- get_sentiments("nrc") %>% 
  filter(sentiment == "negative")

suppressMessages(opinions_neg <- opinions_nrc %>%
  inner_join(nrc_negative) %>%
  count(word, sort = TRUE) %>%
  slice(1:30))

#creating dataset with top30 most frequent words classified as positive
nrc_positive <- get_sentiments("nrc") %>% 
  filter(sentiment == "positive")

suppressMessages(opinions_pos <- opinions_nrc %>%
  inner_join(nrc_positive) %>%
  count(word, sort = TRUE) %>%
  slice(1:30))
```

```{r}
#table of top 30 "negative" words

kable(opinions_neg, col.names = c("Word", "Frequency"), caption = "Top 30 Words in the Student Opinion articles classified as 'negative' in NRC lexicon by frequency") %>%
  kable_styling(font_size = 8) %>%
  row_spec(0,bold=TRUE) 
```

```{r}
#table of top 30 "positive" words

kable(opinions_pos, col.names = c("Word", "Frequency"), caption = "Top 30 Words in the Student Opinion articles classified as 'positive' in NRC lexicon by frequency") %>%
  kable_styling(font_size = 8) %>%
  row_spec(0,bold=TRUE) 
```

# Limitations
The largest limitation to our analysis is perhaps the size of our dataset, which is only 100 articles. The articles only span over the past 9 months, since the start of the 2022-2023 school year. To better examine the breakdown of articles by topic, sentiment, and how sentiment has evolved over time, we would need a much larger database. 
\n 

Another limitation of our analysis is that we only focused on articles from the opinion section of the magazine. The other sections include arts and music, sports, podcasts, and features, meaning these subjects may not appear as frequently in the opinion section. While articles about sports, for example, were not as common in our analysis, readers should not infer this to mean that sports are not frequently written about by Amherst students. 
\n 

It would be nice to generalize our results to make conclusions about the Amherst population as a whole, however, it is important to note that the Student writers may not be an accurate reflection of the entire student body. For instance, while the most common sentiment score was slightly positive, a different set of writers could write much more positively (or much more negatively). 
\n

limitations of the lexicons?

# References

All data sources, any key R packages, and any other sources used in developing your blog should be cited in full in a list of references at the end of your blog. Your blog post should also link to these sources as they are discussed. You may choose any reference style as long as sources are fully cited (try to be consistent!).

Typically, references in R Markdown (and LaTeX) files are [incorporated with a BibTeX database](https://bookdown.org/yihui/rmarkdown-cookbook/bibliography.html) (a .bib file). You can try this approach or manually include either a numbered or alphabetized list. 

Columbia University has compiled some guidance on [how to cite data](https://guides.library.columbia.edu/datacitation). Some data sources will give you the citation information to copy and paste. Use the provided citations or citation styles in those cases.

You can list R package citations with the code `citation("packageName")` in the console and then copy (and reformat as needed) the relevant text, e.g.,
```{r}
citation("DT")
```

The following citations are based on the American Statistical Association citation style (not all of these references are used in this document).:


<!-- Textbook -->
Baumer, B. S., Kaplan, D. T., and Horton, N. J. (2021), *Modern Data Science with R* (2nd ed.), Boca Raton, FL: CRC Press.

<!-- Journal article -->
Broman, K. W. and Woo, K. H. (2018), "Data Organization in Spreadsheets," *The American Statistician*, 72:1, 2-10, doi: [10.1080/00031305.2017.1375989](https://doi.org/10.1080/00031305.2017.1375989)

<!-- Website -->
Columbia University Libraries (n.d.), "Data Citation," available at <https://guides.library.columbia.edu/datacitation>.

<!-- Journal article -->
McNamara, A. and Horton N. J. (2018) "Wrangling Categorical Data in R," *The American Statistician*, 72:1, 97-104, doi: [10.1080/00031305.2017.1356375](https://doi.org/10.1080/00031305.2017.1356375).

<!-- Dataset -->
Shah, Syed A. A. (October 2022), "Starbucks Drinks" (Version 1), *Kaggle*, available at <https://www.kaggle.com/datasets/syedasimalishah/starbucks-drinks>.

<!-- R package -->
Xie Y, Cheng J, Tan X (2022). "DT: A Wrapper of the JavaScript Library 'DataTables'," R package version 0.24, available at <https://CRAN.R-project.org/package=DT>.
  


 


